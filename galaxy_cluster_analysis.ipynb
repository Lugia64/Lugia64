{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing Necessary Libraries\n",
    "We begin by importing Python libraries commonly used in data analysis and visualization:\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib.pyplot` for plotting graphs\n",
    "- `pandas` for handling CSV data, which is especially useful for tabular data such as redshift catalogs\n",
    "\n",
    "> Tip: If you haven't used `pandas` before, it's worth learning as it offers powerful tools to manipulate and analyze structured datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reading big csv files, one can use numpy as well as something called \"pandas\". We suggest to read pandas for CSV file reading and use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G, c\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before we begin calculations, we define key physical constants used throughout:\n",
    "\n",
    "- $ H_0 $: Hubble constant, describes the expansion rate of the Universe.\n",
    "- $c$ : Speed of light.\n",
    "-  $G$: Gravitational constant.\n",
    "- $q_0$ : Deceleration parameter, used for approximate co-moving distance calculations.\n",
    "\n",
    "We will use **`astropy.constants`** to ensure unit consistency and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants:\n",
    "H_0 = cosmo.H0.value  # Hubble constant in km/s/Mpc\n",
    "c_light = c.to('km/s').value  # Speed of light in km/s\n",
    "G_const = G.to('pc3/(kg*s2)').value  # Gravitational constant in pc^3 kg^-1 s^-2\n",
    "q0 = -0.534  # Deceleration parameter (assumed from Planck fit KEEP it as it is)\n",
    "\n",
    "print(f\"H_0 = {H_0} km/s/Mpc\")\n",
    "print(f\"c = {c_light} km/s\")\n",
    "print(f\"G = {G_const} pc^3 kg^-1 s^-2\")\n",
    "print(f\"q_0 = {q0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv data into the python using the method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to point to your actual CSV file\n",
    "csv_file_path = \"your_data_file.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(csv_file_path)\n",
    "print(f\"Data loaded: {len(df)} rows\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Calculating the Average Spectroscopic Redshift (`specz`) for Each Object\n",
    "\n",
    "When working with astronomical catalogs, an object (identified by a unique `objid`) might have multiple entries â€” for example, due to repeated observations. To reduce this to a single row per object, we aggregate the data using the following strategy:\n",
    "\n",
    "```python\n",
    "averaged_df = df.groupby('objid').agg({\n",
    "    'specz': 'mean',        # Take the mean of all spec-z values for that object\n",
    "    'ra': 'first',          # Use the first RA value (assumed constant for the object)\n",
    "    'dec': 'first',         # Use the first Dec value (same reason as above)\n",
    "    'proj_sep': 'first'     # Use the first projected separation value\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average specz for each id:\n",
    "averaged_df = df.groupby('objid').agg({\n",
    "    'specz': 'mean',\n",
    "    'ra': 'first',\n",
    "    'dec': 'first',\n",
    "    'proj_sep': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"After averaging: {len(averaged_df)} unique objects\")\n",
    "print(\"\\nRedshift statistics:\")\n",
    "print(averaged_df.describe()['specz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a cut in the redshift so that a cluster can be identified. We must use some logic. Most astronomers prefer anything beyond 3*sigma away from the mean to be not part of the same group. \n",
    "\n",
    "Find the mean, standard deviation and limits of the redshift from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, standard deviation and 3-sigma limits\n",
    "mean_redshift = averaged_df['specz'].mean()\n",
    "std_redshift = averaged_df['specz'].std()\n",
    "lower_limit = mean_redshift - 3 * std_redshift\n",
    "upper_limit = mean_redshift + 3 * std_redshift\n",
    "\n",
    "print(f\"Mean redshift: {mean_redshift:.4f}\")\n",
    "print(f\"Standard deviation: {std_redshift:.4f}\")\n",
    "print(f\"3-sigma lower limit: {lower_limit:.4f}\")\n",
    "print(f\"3-sigma upper limit: {upper_limit:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use boxplot to visualize the overall values of redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of redshift as histogram and a boxplot \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Boxplot\n",
    "ax1.boxplot(averaged_df['specz'])\n",
    "ax1.set_ylabel('Redshift')\n",
    "ax1.set_title('Boxplot of Redshift Distribution')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram\n",
    "ax2.hist(averaged_df['specz'], bins=30, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(mean_redshift, color='red', linestyle='--', label=f'Mean: {mean_redshift:.3f}')\n",
    "ax2.axvline(lower_limit, color='orange', linestyle='--', label=f'3Ïƒ limits')\n",
    "ax2.axvline(upper_limit, color='orange', linestyle='--')\n",
    "ax2.set_xlabel('Redshift')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Redshift for This Data')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the best plot would be a histogram to see where most of the objects downloaded lie in terms of redshift value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(averaged_df['specz'], bins=90, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(mean_redshift, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_redshift:.3f}')\n",
    "plt.axvline(lower_limit, color='orange', linestyle='--', linewidth=2, label='3Ïƒ limits')\n",
    "plt.axvline(upper_limit, color='orange', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Redshift')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.title('Detailed Histogram of Redshift Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter your data based on the 3-sigma limit of redshift. You should remove all data points which are 3-sigma away from mean of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data based on specz values, used 3 sigma deviation from mean as upper limit.\n",
    "filtered_df = averaged_df[\n",
    "    (averaged_df['specz'] >= lower_limit) & \n",
    "    (averaged_df['specz'] <= upper_limit)\n",
    "].copy()\n",
    "\n",
    "print(f\"Original data: {len(averaged_df)} objects\")\n",
    "print(f\"After 3Ïƒ filtering: {len(filtered_df)} objects\")\n",
    "print(f\"Removed: {len(averaged_df) - len(filtered_df)} objects ({100*(len(averaged_df) - len(filtered_df))/len(averaged_df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the relation between redshift and velocity to add a column named velocity in the data. This would tell the expansion velocity at that redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate velocity using Hubble's law: v = H_0 * c * z / (1 + z) for relativistic correction\n",
    "# For small redshifts, v â‰ˆ c * z\n",
    "filtered_df['velocity'] = c_light * filtered_df['specz']  # km/s\n",
    "\n",
    "print(\"Velocity statistics (km/s):\")\n",
    "print(filtered_df['velocity'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the velocity column created as hist\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_df['velocity'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Velocity (km/s)')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.title('Distribution of Recession Velocities')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the dispersion equation to find something called velocity dispersion. You can even refer to wikipedia to know about the term [wiki link here](https://en.wikipedia.org/wiki/Velocity_dispersion#:~:text=In%20astronomy%2C%20the%20velocity%20dispersion,%2C%20galaxy%20cluster%2C%20or%20supercluster.)\n",
    "\n",
    "It is the velocity dispersion value which tells us, some galaxies might be part of even larger groups!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Mean Redshift of the Cluster\n",
    "We calculate the average redshift (`specz`) of galaxies that belong to a cluster. This gives us an estimate of the cluster's systemic redshift.\n",
    "\n",
    "`cluster_redshift = filtered_df['specz'].mean()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocity dispersion \\( v \\) of galaxies relative to the cluster mean redshift is computed using the relativistic Doppler formula:\n",
    "\n",
    "$$\n",
    "v = c \\cdot \\frac{(1 + z)^2 - (1 + z_{\\text{cluster}})^2}{(1 + z)^2 + (1 + z_{\\text{cluster}})^2}\n",
    "$$\n",
    "where:\n",
    "- \\( v \\) is the relative velocity (dispersion),\n",
    "- \\( z \\) is the redshift of the individual galaxy,\n",
    "- \\( $z_{\\text{cluster}}$ \\) is the mean cluster redshift,\n",
    "- \\( c \\) is the speed of light.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean cluster redshift\n",
    "cluster_redshift = filtered_df['specz'].mean()\n",
    "\n",
    "# Calculate velocity dispersion using relativistic Doppler formula\n",
    "z = filtered_df['specz'].values\n",
    "z_cluster = cluster_redshift\n",
    "\n",
    "# Relativistic velocity dispersion\n",
    "v_dispersion = c_light * ((1 + z)**2 - (1 + z_cluster)**2) / ((1 + z)**2 + (1 + z_cluster)**2)\n",
    "filtered_df['v_dispersion'] = v_dispersion\n",
    "\n",
    "# Calculate the characteristic velocity dispersion (standard deviation)\n",
    "disp = np.std(v_dispersion)\n",
    "\n",
    "print(f\"Cluster mean redshift: {cluster_redshift:.4f}\")\n",
    "print(f\"Velocity dispersion statistics (km/s):\")\n",
    "print(f\"  Standard deviation (Ïƒ): {disp:.1f} km/s\")\n",
    "print(f\"  Mean: {np.mean(v_dispersion):.1f} km/s\")\n",
    "print(f\"  Median: {np.median(v_dispersion):.1f} km/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro tip: Check what the describe function of pandas does. Does it help to get quick look stats for your column of dispersion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas describe function for quick statistics\n",
    "print(\"Velocity dispersion statistics using pandas describe():\")\n",
    "print(filtered_df['v_dispersion'].describe())\n",
    "\n",
    "# Plot histogram of velocity dispersion\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_df['v_dispersion'], bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(0, color='red', linestyle='--', label='Zero velocity')\n",
    "plt.axvline(disp, color='orange', linestyle='--', label=f'Ïƒ = {disp:.1f} km/s')\n",
    "plt.axvline(-disp, color='orange', linestyle='--')\n",
    "plt.xlabel('Velocity Dispersion (km/s)')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.title('Velocity Dispersion Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The value of the cluster redshift = {cluster_redshift:.4f}\")\n",
    "print(f\"The characteristic value of velocity dispersion of the cluster along the line of sight = {disp:.1f} km/s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualizing Angular Separation of Galaxies\n",
    "We plot a histogram of the projected (angular) separation of galaxies from the cluster center. This helps us understand the spatial distribution of galaxies within the cluster field.\n",
    "\n",
    "- The x-axis represents the angular separation (in arcminutes or degrees, depending on units).\n",
    "- The y-axis shows the number of galaxies at each separation bin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for proj_sep column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(filtered_df['proj_sep'], bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Projected Separation (arcmin)')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.title('Distribution of Projected Separations from Cluster Center')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Projected separation statistics:\")\n",
    "print(filtered_df['proj_sep'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining size and mass of the cluster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Estimating Physical Diameter of the Cluster\n",
    "We now estimate the **physical diameter** of the galaxy cluster using cosmological parameters.\n",
    "\n",
    "- `r` is the **co-moving distance**, approximated using a Taylor expansion for low redshift:\n",
    "  $$\n",
    "  r = \\frac{cz}{H_0} \\left(1 - \\frac{z}{2}(1 + q_0)\\right)\n",
    "  $$\n",
    "  where $q_0$ is the deceleration parameter\n",
    "- `ra` is the **angular diameter distance**, given by:\n",
    "  $$\n",
    "  D_A = \\frac{r}{1 + z}\n",
    "  $$\n",
    "- Finally, we convert the observed angular diameter (in arcminutes) into physical size using:\n",
    "  $$\n",
    "  \\text{diameter (in Mpc)} = D_A \\cdot \\theta\n",
    "  $$\n",
    "  where $ \\theta $ is the angular size in radians, converted from arcminutes.\n",
    "\n",
    "> This gives us a rough estimate of the cluster's size in megaparsecs (Mpc), assuming a flat Î›CDM cosmology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comoving distance using Taylor expansion\n",
    "z_cluster = cluster_redshift\n",
    "r_comoving = (c_light * z_cluster / H_0) * (1 - (z_cluster/2) * (1 + q0))  # Mpc\n",
    "\n",
    "# Calculate angular diameter distance\n",
    "D_A = r_comoving / (1 + z_cluster)  # Mpc\n",
    "\n",
    "# Convert maximum projected separation to physical diameter\n",
    "# Assuming the cluster extends to the maximum observed separation\n",
    "max_sep_arcmin = filtered_df['proj_sep'].max()\n",
    "max_sep_radians = max_sep_arcmin * (np.pi / 180) / 60  # Convert arcmin to radians\n",
    "\n",
    "# Physical diameter in Mpc\n",
    "diameter = 2 * D_A * max_sep_radians  # Factor of 2 for diameter\n",
    "\n",
    "print(f\"Cluster redshift: {z_cluster:.4f}\")\n",
    "print(f\"Comoving distance: {r_comoving:.2f} Mpc\")\n",
    "print(f\"Angular diameter distance: {D_A:.2f} Mpc\")\n",
    "print(f\"Maximum projected separation: {max_sep_arcmin:.2f} arcmin\")\n",
    "print(f\"Estimated cluster diameter: {diameter:.2f} Mpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Calculating the Dynamical Mass of the Cluster\n",
    "We now estimate the **dynamical mass** of the galaxy cluster using the virial theorem:\n",
    "\n",
    "$$\n",
    "M_{\\text{dyn}} = \\frac{3 \\sigma^2 R}{G}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\sigma $ is the **velocity dispersion** in m/s (`disp * 1000`),\n",
    "- $ R $ is the **cluster radius** in meters (half the physical diameter converted to meters),\n",
    "- $ G $ is the **gravitational constant** in SI units,\n",
    "- The factor of 3 assumes an isotropic velocity distribution (common in virial estimates).\n",
    "\n",
    "We convert the final result into **solar masses** by dividing by $ 2 \\times 10^{30} \\, \\text{kg} $.\n",
    "\n",
    "> This mass estimate assumes the cluster is in dynamical equilibrium and bound by gravity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the dynamical mass in solar masses:\n",
    "# Convert units properly\n",
    "sigma_ms = disp * 1000  # Convert km/s to m/s\n",
    "R_meters = (diameter * 0.5) * 3.086e22  # Convert Mpc to meters (1 Mpc = 3.086e22 m)\n",
    "G_SI = 6.674e-11  # Gravitational constant in SI units (m^3 kg^-1 s^-2)\n",
    "M_sun = 1.989e30  # Solar mass in kg\n",
    "\n",
    "# Calculate dynamical mass\n",
    "M_dyn = (3 * sigma_ms**2 * R_meters) / G_SI  # Mass in kg\n",
    "M_dyn_solar = M_dyn / M_sun  # Convert to solar masses\n",
    "\n",
    "print(f\"Velocity dispersion: {disp:.1f} km/s = {sigma_ms:.0f} m/s\")\n",
    "print(f\"Cluster radius: {diameter/2:.2f} Mpc = {R_meters:.2e} m\")\n",
    "print(f\"Dynamical Mass of the cluster is {M_dyn_solar:.2e} solar masses\")\n",
    "print(f\"That's approximately {M_dyn_solar/1e14:.1f} Ã— 10^14 solar masses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"GALAXY CLUSTER ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of galaxies analyzed: {len(filtered_df)}\")\n",
    "print(f\"Cluster redshift: {cluster_redshift:.4f}\")\n",
    "print(f\"Velocity dispersion: {disp:.1f} km/s\")\n",
    "print(f\"Cluster diameter: {diameter:.2f} Mpc\")\n",
    "print(f\"Dynamical mass: {M_dyn_solar:.2e} Mâ˜‰\")\n",
    "print(f\"Mass-to-light ratio implications: This is a typical galaxy cluster mass\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compastrolabenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
